{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Automated data pipeline with error handling**"
      ],
      "metadata": {
        "id": "Gjfdsgr-jP2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements"
      ],
      "metadata": {
        "id": "qFTSNSvZjZZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pFDdF-5TzJyi",
        "outputId": "11c861f3-a55f-4d76-faa4-87f69a037b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting prefect\n",
            "  Downloading prefect-2.19.9-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Collecting aiosqlite>=0.17.0 (from prefect)\n",
            "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting alembic<2.0.0,>=1.7.5 (from prefect)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting apprise<2.0.0,>=1.1.0 (from prefect)\n",
            "  Downloading apprise-1.8.1-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asyncpg>=0.23 (from prefect)\n",
            "  Downloading asyncpg-0.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: click<8.2,>=8.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (8.1.7)\n",
            "Requirement already satisfied: cryptography>=36.0.1 in /usr/local/lib/python3.10/dist-packages (from prefect) (42.0.8)\n",
            "Collecting dateparser<2.0.0,>=1.1.1 (from prefect)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting docker>=4.0 (from prefect)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: graphviz>=0.20.1 in /usr/local/lib/python3.10/dist-packages (from prefect) (0.20.3)\n",
            "Collecting griffe<0.48.0,>=0.20.0 (from prefect)\n",
            "  Downloading griffe-0.47.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (3.1.4)\n",
            "Collecting jinja2-humanize-extension>=0.4.0 (from prefect)\n",
            "  Downloading jinja2_humanize_extension-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: humanize>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (4.10.0)\n",
            "Collecting kubernetes<30.0.0,>=24.2.0 (from prefect)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting readchar<5.0.0,>=4.0.0 (from prefect)\n",
            "  Downloading readchar-4.1.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: sqlalchemy!=1.4.33,<3.0.0,>=1.4.22 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy[asyncio]!=1.4.33,<3.0.0,>=1.4.22->prefect) (2.0.31)\n",
            "Requirement already satisfied: typer!=0.12.2,<0.13.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (0.12.3)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from prefect) (3.7.1)\n",
            "Collecting asgi-lifespan<3.0,>=1.0 (from prefect)\n",
            "  Downloading asgi_lifespan-2.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=5.3 in /usr/local/lib/python3.10/dist-packages (from prefect) (5.4.0)\n",
            "Requirement already satisfied: cloudpickle<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (2.2.1)\n",
            "Collecting coolname<3.0.0,>=1.0.4 (from prefect)\n",
            "  Downloading coolname-2.2.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting croniter<3.0.0,>=1.0.12 (from prefect)\n",
            "  Downloading croniter-2.0.7-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (2024.6.1)\n",
            "Collecting httpcore<2.0.0,>=1.0.5 (from prefect)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting httpx!=0.23.2,>=0.23 (from httpx[http2]!=0.23.2,>=0.23->prefect)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting importlib-resources<6.2.0,>=6.1.3 (from prefect)\n",
            "  Downloading importlib_resources-6.1.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting jsonpatch<2.0,>=1.32 (from prefect)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (4.23.0)\n",
            "Collecting orjson<4.0,>=3.7 (from prefect)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m418.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<24.3,>=21.3 in /usr/local/lib/python3.10/dist-packages (from prefect) (24.1)\n",
            "Collecting pathspec>=0.8.0 (from prefect)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pydantic!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pydantic[email]!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.10.0->prefect) (2.8.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (2.20.1)\n",
            "Requirement already satisfied: python-slugify<9.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (8.0.4)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from prefect) (6.0.1)\n",
            "Collecting rfc3339-validator<0.2.0,>=0.1.4 (from prefect)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: rich<14.0,>=11.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (13.7.1)\n",
            "Collecting ruamel.yaml>=0.17.0 (from prefect)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: sniffio<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (1.3.1)\n",
            "Requirement already satisfied: toml>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from prefect) (4.12.2)\n",
            "Collecting ujson<6.0.0,>=5.8.0 (from prefect)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting uvicorn!=0.29.0,>=0.14.0 (from prefect)\n",
            "  Downloading uvicorn-0.30.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<13.0,>=10.4 (from prefect)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: itsdangerous in /usr/local/lib/python3.10/dist-packages (from prefect) (2.2.0)\n",
            "Collecting python-multipart>=0.0.7 (from prefect)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pendulum<3.0 (from prefect)\n",
            "  Downloading pendulum-2.1.2.tar.gz (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Mako (from alembic<2.0.0,>=1.7.5->prefect)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->prefect) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->prefect) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2024.7.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (1.3.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (3.6)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from asyncpg>=0.23->prefect) (4.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.1->prefect) (1.16.0)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser<2.0.0,>=1.1.1->prefect) (2024.5.15)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser<2.0.0,>=1.1.1->prefect) (5.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker>=4.0->prefect) (2.0.7)\n",
            "Collecting colorama>=0.4 (from griffe<0.48.0,>=0.20.0->prefect)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<2.0.0,>=1.0.5->prefect)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting h2<5,>=3 (from httpx[http2]!=0.23.2,>=0.23->prefect)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.0.0->prefect) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.32->prefect)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->prefect) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->prefect) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->prefect) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->prefect) (0.19.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<30.0.0,>=24.2.0->prefect) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes<30.0.0,>=24.2.0->prefect) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<30.0.0,>=24.2.0->prefect) (1.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes<30.0.0,>=24.2.0->prefect) (3.2.2)\n",
            "Collecting pytzdata>=2020.1 (from pendulum<3.0->prefect)\n",
            "  Downloading pytzdata-2020.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.10.0->pydantic[email]!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.10.0->prefect) (0.7.0)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.10.0->prefect)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify<9.0,>=5.0->prefect) (1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=11.0->prefect) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=11.0->prefect) (2.16.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.0->prefect)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy!=1.4.33,<3.0.0,>=1.4.22->sqlalchemy[asyncio]!=1.4.33,<3.0.0,>=1.4.22->prefect) (3.0.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer!=0.12.2,<0.13.0,>=0.12.0->prefect) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.1->prefect) (2.22)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.10.0->prefect)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes<30.0.0,>=24.2.0->prefect) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes<30.0.0,>=24.2.0->prefect) (4.9)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]!=0.23.2,>=0.23->prefect)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]!=0.23.2,>=0.23->prefect)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=11.0->prefect) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->apprise<2.0.0,>=1.1.0->prefect) (3.3.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes<30.0.0,>=24.2.0->prefect) (0.6.0)\n",
            "Downloading prefect-2.19.9-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
            "Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apprise-1.8.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgi_lifespan-2.1.0-py3-none-any.whl (10 kB)\n",
            "Downloading asyncpg-0.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coolname-2.2.0-py2.py3-none-any.whl (37 kB)\n",
            "Downloading croniter-2.0.7-py2.py3-none-any.whl (21 kB)\n",
            "Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-0.47.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.2/122.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.1.3-py3-none-any.whl (34 kB)\n",
            "Downloading jinja2_humanize_extension-0.4.0-py3-none-any.whl (4.8 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading readchar-4.1.0-py3-none-any.whl (9.1 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.4-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.0/490.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: pendulum\n",
            "  Building wheel for pendulum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pendulum: filename=pendulum-2.1.2-cp310-cp310-manylinux_2_35_x86_64.whl size=158446 sha256=72b64904df00ea509b08f83e600e925e248b798643c56e9b566813beda276fad\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/41/ed/f113e4c9dc10f6c846d69f412e9cd9aa429960a3e2e485a4f9\n",
            "Successfully built pendulum\n",
            "Installing collected packages: coolname, websockets, ujson, ruamel.yaml.clib, rfc3339-validator, readchar, pytzdata, python-multipart, pathspec, orjson, Mako, jsonpointer, importlib-resources, hyperframe, hpack, h11, dnspython, colorama, asyncpg, asgi-lifespan, aiosqlite, uvicorn, ruamel.yaml, pendulum, jsonpatch, jinja2-humanize-extension, httpcore, h2, griffe, email-validator, docker, dateparser, croniter, alembic, kubernetes, httpx, apprise, prefect\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.4.0\n",
            "    Uninstalling importlib_resources-6.4.0:\n",
            "      Successfully uninstalled importlib_resources-6.4.0\n",
            "Successfully installed Mako-1.3.5 aiosqlite-0.20.0 alembic-1.13.2 apprise-1.8.1 asgi-lifespan-2.1.0 asyncpg-0.29.0 colorama-0.4.6 coolname-2.2.0 croniter-2.0.7 dateparser-1.2.0 dnspython-2.6.1 docker-7.1.0 email-validator-2.2.0 griffe-0.47.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 importlib-resources-6.1.3 jinja2-humanize-extension-0.4.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-29.0.0 orjson-3.10.6 pathspec-0.12.1 pendulum-2.1.2 prefect-2.19.9 python-multipart-0.0.9 pytzdata-2020.1 readchar-4.1.0 rfc3339-validator-0.1.4 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 ujson-5.10.0 uvicorn-0.30.4 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas prefect\n",
        "!pip install -U prefect\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from prefect import task, flow\n",
        "\n",
        "# Define synthetic data creation task\n",
        "@task\n",
        "def create_synthetic_data():\n",
        "    data = {\n",
        "        'raw_column': ['apple', 'banana', 'cherry', 'date', 'elderberry']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"raw_data.csv\", index=False)\n",
        "    return df\n",
        "\n",
        "# Define data extraction task\n",
        "@task\n",
        "def extract_data():\n",
        "    return pd.read_csv(\"raw_data.csv\")\n",
        "\n",
        "# Define data transformation task\n",
        "@task\n",
        "def transform_data(df):\n",
        "    df['processed_column'] = df['raw_column'].apply(lambda x: x[::-1])\n",
        "    return df\n",
        "\n",
        "# Define data loading task\n",
        "@task\n",
        "def load_data(df):\n",
        "    df.to_csv(\"processed_data.csv\", index=False)\n",
        "\n",
        "# Define the flow\n",
        "@task\n",
        "def send_notification(message):\n",
        "    print(f\"ALERT: {message}\")\n",
        "    # Add your notification logic here\n",
        "\n",
        "def execute_task(task_func, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Execute a task and handle any errors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return task_func(*args, **kwargs)\n",
        "    except Exception as e:\n",
        "        send_notification(f\"{task_func.__name__} failed: {e}\")\n",
        "        raise  # Re-raise the exception to stop the flow\n",
        "\n",
        "# define the flow\n",
        "@flow(name=\"Automated ETL Pipeline\")\n",
        "def etl_pipeline():\n",
        "    try:\n",
        "        raw_data = execute_task(create_synthetic_data)\n",
        "        extracted_data = execute_task(extract_data)\n",
        "        processed_data = execute_task(transform_data, extracted_data)\n",
        "        execute_task(load_data, processed_data)\n",
        "    except Exception as e:\n",
        "        send_notification(f\"Pipeline failed with error: {e}\")\n",
        "\n",
        "# Run the flow\n",
        "etl_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "bpHNGAFBDCqg",
        "outputId": "b425f0cb-f094-4b99-97ab-c134c4fa1f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.311 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'spectral-groundhog'\u001b[0m for flow\u001b[1;35m 'Automated ETL Pipeline'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.311 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Automated ETL Pipeline'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.443 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Created task run 'create_synthetic_data-0' for task 'create_synthetic_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.443 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Created task run 'create_synthetic_data-0' for task 'create_synthetic_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.446 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Executing 'create_synthetic_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.446 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Executing 'create_synthetic_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.582 | \u001b[36mINFO\u001b[0m    | Task run 'create_synthetic_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.582 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'create_synthetic_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.631 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Created task run 'extract_data-0' for task 'extract_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.631 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Created task run 'extract_data-0' for task 'extract_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.634 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Executing 'extract_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.634 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Executing 'extract_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.758 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.758 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.809 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Created task run 'transform_data-0' for task 'transform_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.809 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Created task run 'transform_data-0' for task 'transform_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.813 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Executing 'transform_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.813 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Executing 'transform_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.947 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.947 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:52.999 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Created task run 'load_data-0' for task 'load_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:52.999 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Created task run 'load_data-0' for task 'load_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:53.002 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Executing 'load_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:53.002 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Executing 'load_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:53.135 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:53.135 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:54:53.206 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'spectral-groundhog'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:54:53.206 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'spectral-groundhog'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DataFrame`')),\n",
              " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DataFrame`')),\n",
              " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DataFrame`')),\n",
              " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`'))]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic monitoring in a data pipeline**"
      ],
      "metadata": {
        "id": "2axnruo9kZ5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "UM2ymVC1kmMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nDjWM1AukWiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define synthetic data creation task\n",
        "@task\n",
        "def create_synthetic_data():\n",
        "    np.random.seed(42)\n",
        "    data = {\n",
        "        'raw_column': np.random.choice(['apple', 'banana', 'cherry', 'date', 'elderberry'], 1000),\n",
        "        'numeric_feature': np.random.randint(1, 100, 1000),\n",
        "        'float_feature': np.random.uniform(0, 1, 1000)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"raw_data.csv\", index=False)\n",
        "    print(f\"Created synthetic dataset with {len(df)} records\")\n",
        "    return df\n",
        "\n",
        "# Define data extraction task\n",
        "@task\n",
        "def extract_data():\n",
        "    # Simulating data extraction\n",
        "    df = pd.read_csv(\"raw_data.csv\")\n",
        "    print(f\"Extracted {len(df)} records\")\n",
        "    return df\n",
        "\n",
        "# Transformation function\n",
        "def some_transformation(x):\n",
        "    return x.upper()\n",
        "\n",
        "# Define data transformation task\n",
        "@task\n",
        "def transform_data(df):\n",
        "    # Performing data transformations\n",
        "    df['processed_column'] = df['raw_column'].apply(some_transformation)\n",
        "    df['numeric_squared'] = df['numeric_feature'] ** 2\n",
        "    df['float_rounded'] = df['float_feature'].round(2)\n",
        "    print(f\"Transformed {len(df)} records\")\n",
        "    return df\n",
        "\n",
        "# Define data loading task\n",
        "@task\n",
        "def load_data(df):\n",
        "    # Simulating data loading\n",
        "    df.to_csv(\"processed_data.csv\", index=False)\n",
        "    print(f\"Loaded {len(df)} records\")\n",
        "\n",
        "# Define data quality monitoring task\n",
        "@task\n",
        "def monitor_data_quality(df):\n",
        "    # Basic data quality checks\n",
        "    assert df['processed_column'].isnull().sum() == 0, \"Null values detected in processed_column\"\n",
        "    assert df['numeric_squared'].isnull().sum() == 0, \"Null values detected in numeric_squared\"\n",
        "    assert df['float_rounded'].isnull().sum() == 0, \"Null values detected in float_rounded\"\n",
        "    assert len(df) > 0, \"Empty dataframe detected\"\n",
        "    print(\"Data quality checks passed\")\n",
        "\n",
        "# Define the flow using Prefect 2.x\n",
        "@flow(name=\"Monitored ETL Pipeline\")\n",
        "def etl_pipeline():\n",
        "    # Create synthetic data\n",
        "    synthetic_data = create_synthetic_data()\n",
        "\n",
        "    # Extract data\n",
        "    raw_data = extract_data()\n",
        "\n",
        "    # Transform data\n",
        "    processed_data = transform_data(raw_data)\n",
        "\n",
        "    # Monitor data quality\n",
        "    monitor_data_quality(processed_data)\n",
        "\n",
        "    # Load data\n",
        "    load_data(processed_data)\n",
        "\n",
        "# Run the flow\n",
        "etl_pipeline()\n",
        "\n",
        "# Display the first few rows of the processed data\n",
        "processed_df = pd.read_csv(\"processed_data.csv\")\n",
        "print(\"\\nFirst few rows of processed data:\")\n",
        "print(processed_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "F7uwmZ6WDDgC",
        "outputId": "f775bc34-34db-458b-9d7e-31e932f3fef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:12.933 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'colossal-stork'\u001b[0m for flow\u001b[1;35m 'Monitored ETL Pipeline'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:12.933 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Monitored ETL Pipeline'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.066 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Created task run 'create_synthetic_data-0' for task 'create_synthetic_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.066 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Created task run 'create_synthetic_data-0' for task 'create_synthetic_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.069 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Executing 'create_synthetic_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.069 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Executing 'create_synthetic_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created synthetic dataset with 1000 records\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.214 | \u001b[36mINFO\u001b[0m    | Task run 'create_synthetic_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.214 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'create_synthetic_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.278 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Created task run 'extract_data-0' for task 'extract_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.278 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Created task run 'extract_data-0' for task 'extract_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.282 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Executing 'extract_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.282 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Executing 'extract_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 1000 records\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.430 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.430 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.497 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Created task run 'transform_data-0' for task 'transform_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.497 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Created task run 'transform_data-0' for task 'transform_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.503 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Executing 'transform_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.503 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Executing 'transform_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed 1000 records\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.743 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.743 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.828 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Created task run 'monitor_data_quality-0' for task 'monitor_data_quality'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.828 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Created task run 'monitor_data_quality-0' for task 'monitor_data_quality'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:13.842 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Executing 'monitor_data_quality-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:13.842 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Executing 'monitor_data_quality-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data quality checks passed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:14.040 | \u001b[36mINFO\u001b[0m    | Task run 'monitor_data_quality-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:14.040 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'monitor_data_quality-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:14.119 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Created task run 'load_data-0' for task 'load_data'\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:14.119 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Created task run 'load_data-0' for task 'load_data'\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:14.131 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Executing 'load_data-0' immediately...\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:14.131 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Executing 'load_data-0' immediately...\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1000 records\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:14.400 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:14.400 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10:55:14.502 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'colossal-stork'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">10:55:14.502 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'colossal-stork'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First few rows of processed data:\n",
            "   raw_column  numeric_feature  float_feature processed_column  \\\n",
            "0        date               76       0.125742             DATE   \n",
            "1  elderberry               68       0.132715       ELDERBERRY   \n",
            "2      cherry                5       0.143542           CHERRY   \n",
            "3  elderberry               37       0.939820       ELDERBERRY   \n",
            "4  elderberry               72       0.732899       ELDERBERRY   \n",
            "\n",
            "   numeric_squared  float_rounded  \n",
            "0             5776           0.13  \n",
            "1             4624           0.13  \n",
            "2               25           0.14  \n",
            "3             1369           0.94  \n",
            "4             5184           0.73  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple example of how structured data might be represented and processed**"
      ],
      "metadata": {
        "id": "P7tu8B50lQtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import important libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "q9X2rU1llSQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of structured data\n",
        "data = pd.DataFrame({\n",
        "    'customer_id': [1, 2, 3, 4, 5],\n",
        "    'age': [28, 35, 42, 50, 33],\n",
        "    'tenure': [12, 24, 36, 48, 6],\n",
        "    'monthly_charge': [50.0, 70.0, 100.0, 80.0, 65.0],\n",
        "    'churn': [0, 0, 1, 1, 0]\n",
        "})\n",
        "\n",
        "# Easy to perform operations on structured data\n",
        "X = data[['age', 'tenure', 'monthly_charge']]\n",
        "y = data['churn']\n",
        "\n",
        "# Simple to use in machine learning models\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "#Evaluate model\n",
        "print(\"Model accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "fRYMAJXte27M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979b2c61-4114-4753-d395-611aa862bdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple example of processing unstructured text data**"
      ],
      "metadata": {
        "id": "Hk0SKVBcmJdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install nltk\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFvuJfwfliFm",
        "outputId": "6c895658-1a1e-4dc9-8f32-a60456f7fc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "JsfmHvoLlc2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Remove stopwords and non-alphabetic tokens\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Example unstructured data\n",
        "customer_review = \"\"\"\n",
        "The product was great! It arrived on time and the quality exceeded my expectations.\n",
        "However, the customer service could use some improvement. Overall, I’m satisfied.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocess the example text\n",
        "processed_tokens = preprocess_text(customer_review)\n",
        "print(\"Processed Tokens:\", processed_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaCta9w_lczT",
        "outputId": "e4e47af8-1a28-4026-a1dd-8d5907804b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Tokens: ['product', 'great', 'arrived', 'time', 'quality', 'exceeded', 'expectations', 'however', 'customer', 'service', 'could', 'use', 'improvement', 'overall', 'satisfied']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    }
  ]
}